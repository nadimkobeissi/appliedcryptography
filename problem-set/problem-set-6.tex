\documentclass[10pt,a4paper,american]{exam}
\usepackage{../misc/macros/classhandout}

\title{Applied Cryptography - Problem Set 6: High-Assurance Cryptography}
\author{Nadim Kobeissi}
\subject{Problem set covering high-assurance cryptography topics including formal verification methods, symbolic vs computational models, side-channel resistance, and practical deployment of verified cryptographic systems.}
\keywords{formal verification, ProVerif, CryptoVerif, symbolic model, computational model, side channels, constant-time implementation, HACL*, protocol verification, equivalence properties}

\begin{document}
\classhandoutheader
\section*{Problem Set 6: High-Assurance Cryptography}

\begin{tcolorbox}[colframe=OliveGreen!30!white,colback=OliveGreen!5!white]
	\textbf{Instructions:} This problem set covers topics in high-assurance cryptography and formal verification methods from topic 2.5\footnote{\url{https://appliedcryptography.page/slides/\#2-5}} of the course. Submit your solutions as a neatly formatted PDF. You are encouraged to collaborate with classmates in studying the material, but your submitted solutions must be your own work. For proofs, clearly state your assumptions, steps, and conclusions.
\end{tcolorbox}

\section{Design-Level Security and Formal Verification}
\begin{questions}
	\subsection*{Symbolic vs. Computational Models}

	\question[12] \textbf{Protocol Modeling Trade-offs:}
	You are tasked with formally verifying a new secure messaging protocol for a government agency. The protocol involves complex key derivation, multiple handshake modes, and post-compromise security guarantees.
	\begin{parts}
		\part Compare the advantages and limitations of using symbolic (ProVerif) versus computational (CryptoVerif) approaches for this protocol. Which properties would be easier to verify in each model?
		\part The protocol uses a custom authenticated encryption scheme. Explain, at a high level, how such a construction would be modeled in the symbolic model. What assumptions would you need to make?
	\end{parts}

	\question[12] \textbf{Equivalence Properties in Practice:}
	A voting protocol claims to provide receipt-freeness: voters cannot prove how they voted, even if they want to.

	\textbf{Background:} Recall that security properties in formal verification can be classified as:
	\begin{itemize}
		\item \textbf{Trace properties}: Properties that can be verified by examining individual execution traces (e.g., ``the secret key is never sent in plaintext'')
		\item \textbf{Equivalence properties}: Properties that require comparing multiple executions (e.g., ``an attacker cannot distinguish between two different scenarios'')
	\end{itemize}

	Receipt-freeness means that even if Alice wants to prove she voted for candidate A (perhaps under coercion), she cannot produce evidence that distinguishes her voting for A from voting for B. This inherently involves comparing two scenarios.

	\begin{parts}
		\part[6] Explain why receipt-freeness cannot be expressed as a trace property.\footnote{Hint: Consider what information would need to be examined in a single trace versus across multiple traces.} Then formulate receipt-freeness as an equivalence property in the symbolic model.\footnote{Hint: Think about what two processes should be indistinguishable to model this property.}
		\part[6] There exist different notions of equivalence:\footnote{\url{https://appliedcryptography.page/paper/\#sok-verif}}
		\begin{itemize}
			\item \textbf{Trace equivalence}: Two processes are equivalent if they produce the same set of observable traces.
			\item \textbf{Open bisimilarity}: A stronger notion where processes must match each other's behavior step-by-step, even when the attacker provides inputs.
			\item \textbf{Diff-equivalence}: The strongest (most restrictive) notion where two protocols must have identical structure, differing only in the messages exchanged. All tests must succeed or fail identically in both protocols, preserving protocol structure during execution.
		\end{itemize}
		Compare these three approaches for modeling receipt-freeness. Which would be most appropriate and why? What can you say about the analysis's precision of the analysis and the computational complexity?
	\end{parts}

	\subsection*{Tool Selection and Application}

	\question[10] \textbf{ProVerif Analysis Challenge:}
	You're analyzing a protocol that combines TLS 1.3 with a custom post-quantum key exchange mechanism.
	\begin{parts}
		\part[5] ProVerif's analysis time explodes when modeling protocols that generate many ephemeral keys. Explain why certain cryptographic patterns (like generating fresh keys for each message) are harder to analyze symbolically than others (like reusing long-term keys).
		\part[5] To make ProVerif analysis terminate in a shorter time period, you may need to simplify the protocol model. Describe two specific simplifications you would make (e.g., bounding the number of sessions, abstracting the post-quantum KEM as a perfect encryption scheme, or modeling only a subset of TLS 1.3 features). For each simplification, explain what attacks it might miss.
	\end{parts}
\end{questions}

\section{Implementation Security and Side Channels}
\begin{questions}
	\subsection*{Constant-Time Implementation}

	\question[8] \textbf{Compiler and Hardware Challenges:}
	AES implementations commonly use lookup tables (S-boxes) for the SubBytes operation, where table indices depend on secret key material XORed with plaintext. This creates timing variations through cache hits/misses that can leak key bits.

	You've written constant-time code for AES, carefully avoiding these vulnerabilities by eliminating table lookups (perhaps using bit-slicing), key-dependent branches, and variable-time operations.
	\begin{parts}
		\part[4] Give three specific examples of how a modern compiler might destroy your constant-time guarantees through ``optimization.'' For each, show the original code and the problematic transformation.
		\part[4] Even with perfect constant-time assembly code, modern CPUs introduce timing variations. Explain how branch predictors can leak information even when your code has no explicit branches. Analyze the trade-offs between different constant-time implementation strategies (bit-slicing, masking, vectorization) in the presence of micro-architectural attacks.
	\end{parts}

	\subsection*{Side-Channel Resistance}

	\question[8] \textbf{Understanding Leakage Models:}
	You're implementing cryptographic primitives and need to ensure they're resistant to side-channel attacks.
	\begin{parts}
		\part[4] Explain the three main leakage models covered in the course: program counter (PC) model, constant-time model, and size-respecting model. For each model, describe what information leaks and give a concrete example of a coding pattern that would violate it.
		\part[4] Consider this password checking code:
		\begin{verbatim}
for (i = 0; i < len; i++) {
				if (password[i] != input[i]) {
								return FAIL;
				}
}
return SUCCESS;
\end{verbatim}
		Explain why this violates constant-time principles and show how to rewrite it to be constant-time. What is the performance trade-off?
	\end{parts}
\end{questions}

\section{Computer-Aided Cryptography in Practice}
\begin{questions}
	\subsection*{Verification Case Studies}

	\question[10] \textbf{\haclstar Success Story:}
	Mozilla integrated \haclstar into Firefox, replacing hand-written assembly with verified \fstar code.
	\begin{parts}
		\part[5] Analyze why \haclstar succeeded where previous verification efforts failed. Consider performance, API compatibility, and development process.
		\part[5] The \haclstar team claims ``verification for free'' - no performance penalty. Examine this claim critically. What optimizations might verified code miss compared to expert assembly? Design a gradual migration strategy for replacing OpenSSL with verified implementations.
	\end{parts}

	\question[10] \textbf{hax and the Future of Verification:}
	The hax toolchain\footnote{\url{https://hax.cryspen.com}} promises to extract formal models from Rust implementations.
	\begin{parts}
		\part[5] Analyze the benefits and risks of extracting ProVerif models from implementation code versus writing them manually. What semantic gaps might arise?
		\part[5] Design a development workflow using hax that ensures both protocol-level and implementation-level security. How do you maintain consistency as the code evolves?
	\end{parts}

	\subsection*{Building Verified Systems}

	\question[10] \textbf{Multiple Cipher Suites Challenge:}
	Consider a secure messaging protocol that supports three different cipher suites:
	\begin{itemize}
		\item Suite A: AES-128-GCM with RSA-2048
		\item Suite B: AES-256-GCM with ECDH-P256
		\item Suite C: ChaCha20-Poly1305 with Ed25519
	\end{itemize}

	\begin{parts}
		\part[5] The protocol allows parties to negotiate which cipher suite to use during the handshake. What new attack vectors does this negotiation introduce? How would you model cipher suite negotiation in ProVerif to catch downgrade attacks?
		\part[5] You need to formally verify the security of the protocol described above. Describe how you would structure the verification to avoid analyzing all possible combinations of sender/receiver cipher suite choices. What common security properties can you abstract across all cipher suites?
	\end{parts}

	\question[20] \textbf{End-to-End Verification Project:}
	You're leading the verification of a new secure communication protocol that will be deployed at nation-state scale. The protocol combines classical and post-quantum cryptography, supports multiple authentication modes, and must resist both computational and side-channel attacks.
	\begin{parts}
		\part[5] \textbf{Verification Architecture:}
		Design a comprehensive verification strategy using multiple tools. Specify which properties each tool will verify and identify gaps between different verification layers.

		\part[5] \textbf{Formal Specifications:}
		Write formal security definitions for the protocol's goals. Specify side-channel resistance requirements formally.

		\part[5] \textbf{Implementation Strategy:}
		Choose implementation languages and verification tools. Design the development workflow to maintain verification.

		\part[5] \textbf{Assurance Arguments:}
		Create a comprehensive assurance case for stakeholders. Address the ``fine print'' - what's not verified and why. Design a maintenance strategy for evolving threats.
	\end{parts}
\end{questions}

\begin{tcolorbox}[colframe=EarthBrown!30!white,colback=EarthBrown!5!white]
	\section*{Bonus Question}
	\begin{questions}
		\bonusquestion[20] Allen Gumm, a rather sticky fellow who gets trapped by his own bubble gum-based weapons and constantly has to unstick himself from walls, has usurped power at a cryptography company. The company's products use formally verified components: \haclstar for cryptographic primitives and hand-written ProVerif models for protocol verification. Despite these verification efforts, Allen wants to subvert their security without detection.

		Analyze which elements of the cryptography stack Allen Gumm could compromise that would bypass the formal verification guarantees:
		\begin{parts}
			\part[10] \textbf{Beyond the Verification Boundary:} Identify at least three components or interfaces that typically fall outside the formal verification scope outlined above but are critical for security. For each, explain how Allen could introduce vulnerabilities and why the verification wouldn't catch them.

			\part[10] \textbf{Trust Assumptions:} Formal verification relies on various trust assumptions. List specific assumptions made by \haclstar and ProVerif that Allen could violate in practice. How could he exploit the gap between the formal model and the deployed system?

			\part[10] \textbf{Deployment Sabotage:} Even with verified code and protocols, deployment introduces new attack surfaces. Propose three realistic ways Allen could compromise the system during build, deployment, or runtime without modifying the verified components themselves. What additional verification or monitoring would be needed to detect his sticky schemes?
		\end{parts}

		Your analysis should be concrete and technically sound, focusing on practical vulnerabilities rather than theoretical limitations. Consider real-world deployment scenarios and the boundaries of current verification technology.
	\end{questions}
\end{tcolorbox}

\end{document}
